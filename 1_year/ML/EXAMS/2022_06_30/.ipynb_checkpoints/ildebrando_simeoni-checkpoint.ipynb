{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cf9d39",
   "metadata": {},
   "source": [
    "Importing useful libraries and setting the random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "980bd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, cohen_kappa_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234f560",
   "metadata": {},
   "source": [
    "## POINT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482264c5",
   "metadata": {},
   "source": [
    "Loading the data, replacing '?' character with the proper coding of nulls (i.e. np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1267cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('horse-colic.csv', header = None)\n",
    "df = df.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e9337",
   "metadata": {},
   "source": [
    "Renaming the columns to numbers starting from 1, as shown in the description file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "41cc510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = range(1,29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54be3f0",
   "metadata": {},
   "source": [
    "Removing columns named 3, 25, 26, 27, 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "4ebf8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([3,25,26,27,28], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff5d8f",
   "metadata": {},
   "source": [
    "Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "6ff5c0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.50</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>45.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.30</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>39.10</td>\n",
       "      <td>164</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.00</td>\n",
       "      <td>7.20</td>\n",
       "      <td>3</td>\n",
       "      <td>5.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.30</td>\n",
       "      <td>104</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.00</td>\n",
       "      <td>7.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  1   2      4    5   6    7    8    9  10   11  ...   15    16   17   18  \\\n",
       "0  2   1  38.50   66  28    3    3  NaN  2    5  ...  NaN   NaN    3    5   \n",
       "1  1   1   39.2   88  20  NaN  NaN    4  1    3  ...  NaN   NaN    4    2   \n",
       "2  2   1  38.30   40  24    1    1    3  1    3  ...  NaN   NaN    1    1   \n",
       "3  1   9  39.10  164  84    4    1    6  2    2  ...    2  5.00    3  NaN   \n",
       "4  2   1  37.30  104  35  NaN  NaN    6  2  NaN  ...  NaN   NaN  NaN  NaN   \n",
       "\n",
       "      19    20   21    22 23 24  \n",
       "0  45.00  8.40  NaN   NaN  2  2  \n",
       "1     50    85    2     2  3  2  \n",
       "2  33.00  6.70  NaN   NaN  1  2  \n",
       "3  48.00  7.20    3  5.30  2  1  \n",
       "4  74.00  7.40  NaN   NaN  2  2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042cfaf1",
   "metadata": {},
   "source": [
    "Showing the count of nulls for each remaining column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a94956f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       1\n",
       "2       0\n",
       "4      60\n",
       "5      24\n",
       "6      58\n",
       "7      56\n",
       "8      69\n",
       "9      47\n",
       "10     32\n",
       "11     55\n",
       "12     44\n",
       "13     56\n",
       "14    104\n",
       "15    106\n",
       "16    247\n",
       "17    102\n",
       "18    118\n",
       "19     29\n",
       "20     33\n",
       "21    165\n",
       "22    198\n",
       "23      1\n",
       "24      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd9860",
   "metadata": {},
   "source": [
    "## POINT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8a1ea",
   "metadata": {},
   "source": [
    "Using column 23 as target for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "e0018e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9cb557",
   "metadata": {},
   "source": [
    "Dropping rows where the target is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "78b28a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, subset=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d20cb0",
   "metadata": {},
   "source": [
    "Storing column names of all the columns except target one in order to reutilize those after the Imputing fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "137d8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.loc[:, df.columns != target].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8b0be",
   "metadata": {},
   "source": [
    "Imputing the nulls on the predicting columns using the column means via sklearn.impute.SimpleImputer (i.e. replacing missing values using the mean along each column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "5e80d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df_predicting = pd.DataFrame(imputer.fit_transform(df.loc[:, df.columns != target]), columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a5379",
   "metadata": {},
   "source": [
    "Separing the dataset into the predicting and target parts X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d9dbd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_predicting\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec949e3",
   "metadata": {},
   "source": [
    "## POINT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a98f4",
   "metadata": {},
   "source": [
    "Splitting the dataset into trainin and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "0fddd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f4ba5",
   "metadata": {},
   "source": [
    "Training, tuning and testing a  Decision Tree classification model with crossâ€“validation via GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "aa8842cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'accuracy'\n",
    "cv = 5 #number of split for cross validation\n",
    "model_param = {'criterion':['gini', 'entropy'], 'max_depth':list(range(1,10)), 'min_samples_split': range(2,10)}\n",
    "model_est = DecisionTreeClassifier(random_state=random_state)\n",
    "\n",
    "model = GridSearchCV(model_est, model_param, scoring=score, cv=5) \n",
    "model.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a092dd7",
   "metadata": {},
   "source": [
    "Plotting the resulting confusion matrix on the test set, normalising for true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "4c1ab8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[0.8372093  0.13953488 0.02325581]\n",
      " [0.4        0.6        0.        ]\n",
      " [0.58333333 0.33333333 0.08333333]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, y_pred, normalize = 'true')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef689190",
   "metadata": {},
   "source": [
    "Showing the values F1-Score (macro) speficing it as average, and Cohen Kappa Score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "4b601244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4934143870314083\n"
     ]
    }
   ],
   "source": [
    "f1_model1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f1_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "09bba75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34299191374663085\n"
     ]
    }
   ],
   "source": [
    "cohen_kappa_model1 = cohen_kappa_score(y_test, y_pred)\n",
    "print(cohen_kappa_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da660e91",
   "metadata": {},
   "source": [
    "## POINT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad12787",
   "metadata": {},
   "source": [
    "Repeating step 3 with a KNeighborsClassifier rather then a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "54ca1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'accuracy'\n",
    "cv = 5 #number of split for cross validation\n",
    "model2_param = [{\"n_neighbors\": list(range(1, 16))}]\n",
    "model2_est = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "model2 = GridSearchCV(model2_est, model2_param, scoring=score, cv=5) \n",
    "model2.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "3b5d5431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[0.88372093 0.11627907 0.        ]\n",
      " [0.6        0.35       0.05      ]\n",
      " [0.5        0.33333333 0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, y_pred2,normalize = 'true')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "3eb67162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4744107744107744\n"
     ]
    }
   ],
   "source": [
    "f1_model2 = f1_score(y_test, y_pred2, average='macro')\n",
    "print(f1_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "7c6905dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2659909122684375\n"
     ]
    }
   ],
   "source": [
    "cohen_kappa_model2 = cohen_kappa_score(y_test, y_pred2)\n",
    "print(cohen_kappa_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1fd9c",
   "metadata": {},
   "source": [
    "## POINT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7249034",
   "metadata": {},
   "source": [
    "Given the comparison of the results obtained via f1 scores and cohen_kappa_score the first model (i.e. the Decision Tree Classifier) has been selected.\n",
    "In particular with an higher value of f1 score (i.e. an harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0) the Decision tree shows a slightly better result.\n",
    "On the other hand the not so sligthly difference with respect to the cohen_kappa_score (i.e. a number between -1 and 1 that expresses the level of agreement between two annotators on a classification problem, with maximum value means complete agreement; zero or lower means chance agreement) is what let me easly choose between the two classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "22a2ae7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between model scores: the f1 score of model 1 is 0.4934143870314083 wrt model 2 0.4744107744107744. The cohen kappa scores are: 0.34299191374663085 and 0.2659909122684375 \n"
     ]
    }
   ],
   "source": [
    "print(f'Comparison between model scores: the f1 score of model 1 is {f1_model1} wrt model 2 {f1_model2}. The cohen kappa scores are: {cohen_kappa_model1} and {cohen_kappa_model2} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131745de",
   "metadata": {},
   "source": [
    "In this case an easy to implement approach with tuned Decision Tree perform better than a KNN approach as seen here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
